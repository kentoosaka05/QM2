{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kentoosaka05/QM2/blob/main/W2_Working_with_Data_in_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh0t7NbNOgk5"
      },
      "source": [
        "# Intro to Pandas\n",
        "\n",
        "## *Workshop 2*  [![Open In Colab](https://github.com/oballinger/QM2/blob/main/colab-badge.png?raw=1)](https://colab.research.google.com/github/oballinger/QM2/blob/main/notebooks/W02.%20Pandas.ipynb)\n",
        "\n",
        "\n",
        "In this workshop, our aim is to get used to working with more complex data that we've imported from external files. We'll start to graph it, and to slice and dice it, to select the bits we're interested in.\n",
        "\n",
        "We will work with *pandas* to manipulate the data, and to derive measures and graphs that tell us a bit more than what the source data files tell us.\n",
        "\n",
        "### Aims\n",
        "\n",
        "- Learn to import data to python using pandas\n",
        "- Learn how access specific rows, columns and cells\n",
        "- Plot the data\n",
        "- Tidy up graphs to include axes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wnaRCMaOgk6"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "We are going to work with some UK income data. The income data is packaged as a .csv file. The Pandas package knows how to handle this and put the data in a DataFrame, as we've seen. Let's examine the data and start to see what we can say about it. First of all, we have to find data - I'm interested in looking in data with a wide spread, so I looked for data on income in the UK.\n",
        "\n",
        "This data is collected by the Office for National Statistics(ONS) : http://www.ons.gov.uk/ons/datasets-and-tables/index.html?pageSize=50&sortBy=none&sortDirection=none&newquery=income+percentile - but the exact data I want to see, income by percentile, is tricky to find.\n",
        "\n",
        "I ended up using data from 2011, generated from a study called the Family Resources Survey and collated and tweaked by an independent research unit called the Institute of Fiscal Studies (IFS). The \"tweaking\" they do tends to be around the size of the family unit, and other factors which create economies of scale - hence they \"equivalise\" it. The IFS is quoted in UK Government documents, so we can have some trust in their impartiality, or at least accuracy - of course, if we were publishing research about this, that's not really good enough and we'd want to reproduce, or at least understand and critique, their methodology rather than just trusting it!\n",
        "\n",
        "e.g.:\n",
        "\n",
        "http://www.ifs.org.uk/wheredoyoufitin/about.php\n",
        "\n",
        "https://en.wikipedia.org/wiki/Equivalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsF6sfaWOgk7"
      },
      "source": [
        "## Downloading the Data\n",
        "\n",
        "Let's grab our income data from our course website and save it into our data folder.  If you've not already created a data folder then do so using the following command.  Don't worry if it generates an error, that means you've already got a data folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWXVYQmlOgk7"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSISKOHUOglB"
      },
      "outputs": [],
      "source": [
        "!mkdir data/wk2\n",
        "!curl https://s3.eu-west-2.amazonaws.com/qm2/wk2/incomes.csv -o ./data/wk2/incomes.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bsU0xgcOglF"
      },
      "source": [
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cBMkYbaOglG"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import pylab\n",
        "import matplotlib.pyplot as plt\n",
        "# make the plots a little wider by default\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "pylab.rcParams['figure.figsize'] = (10., 8.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD2qMhAxOglK"
      },
      "outputs": [],
      "source": [
        "data_path = \"./data/wk2/incomes.csv\"\n",
        "\n",
        "income =  pandas.read_csv(data_path, index_col=0)\n",
        "income.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwBN9m9BOglN"
      },
      "source": [
        "This is a simple dataframe - we see the percentile and an income. Note that I've told pandas to use the first column (the Percentile) as the index to make life easier.\n",
        "\n",
        "The percentile tells us how people on that income rank - so the final category, 99% (which is really binned, so 99%<n$\\leq$ 100%), is telling us how much \"the 1%\" earn. Let's find out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqAN20onOglN"
      },
      "outputs": [],
      "source": [
        "income.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvoYh43VOglQ"
      },
      "source": [
        "Well, they we have it - the 1% earn, on average, about £2000 a week. How does that compare to people in the 90% decile? We can access particular *rows* in a dataframe using **.loc[row index]**; because our index is the percentile point, we can just read it off:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amopH87LOglQ"
      },
      "outputs": [],
      "source": [
        "income.loc[90]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9-QS6W4OglU"
      },
      "source": [
        "We can also select a range of values with the \"colon\" notation. This will select the 90-95th percentiles, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJDvuHzvOglU"
      },
      "outputs": [],
      "source": [
        "income.loc[90:95]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dgcOIQeOglW"
      },
      "source": [
        "## Accessing parts of a dataframe\n",
        "\n",
        "If we want to extract the actual value instead of just the whole row, we need to reference the *column* as well as the row. In pandas, columns are referenced by **column name**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9tXjsnGOglW"
      },
      "outputs": [],
      "source": [
        "income['Net equivalised household income in 2010-11, week']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-9Rh1x1OglZ"
      },
      "source": [
        "So, to access a particular cell, we tell Python the row and the column (this is pretty simple - the same way we tell excel to access cell \"A34\" meaning Column A, Row 34). One way we do that in pandas is to select the column, and then use .loc[] on the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e7BrLoCOglZ"
      },
      "outputs": [],
      "source": [
        "income['Net equivalised household income in 2010-11, week'].loc[90]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TBCVuLQOglc"
      },
      "source": [
        "We've accessed row 90 of the column called 'Net equivalised household income in 2010-11, week'; can we access the data the other way around - can we first take the row and then specify a column? Let's try:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Ix_HYPOglc"
      },
      "outputs": [],
      "source": [
        "income.loc[90]['Net equivalised household income in 2010-11, week']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrLFa4LjOgle"
      },
      "source": [
        "Yes, this seems to be working fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn1SslxTOglf"
      },
      "source": [
        "### Extension\n",
        "\n",
        "The reason for this is that selecting the column spits out a smaller dataframe, and all dataframes use  \"loc\", so we can use that. Another way to do this would be to use an explicit variable for the dataframe, along the lines of:\n",
        "\n",
        "`smallDataFrame = income['Net equivalised household income in 2010-11, week']`  \n",
        "`smallDataFrame.loc[90]`\n",
        "\n",
        "by doing income\n",
        "\n",
        "`['Net equivalised household income in 2010-11, week'].loc[90]`   \n",
        "\n",
        "we're taking the \"smallDataFrame\" object as an implicit (or hidden) output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZeXYNIAOglf"
      },
      "source": [
        "If we want to look at a few rows of data, we can use a range:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYBoACruOglg"
      },
      "outputs": [],
      "source": [
        "income['Net equivalised household income in 2010-11, week'].loc[90:95]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocHXwl23Oglk"
      },
      "source": [
        "So, to recap, we can now access a particular **row** using *loc[index number]*, a particular **column** with the square brackets formalism *dataframename['column name']*, or both *dataframename['column name'].loc[index number]*. We've made a start at being able to get to the bits of data we need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuUywdOYOgll"
      },
      "source": [
        "## Exercise:\n",
        "    \n",
        "How do the equivalised incomes of single adults and childless couples compare? Look at the 1st, 99th and 50th percentile and summarise what this tells you about the value or price of coupling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajwfDhieOgll"
      },
      "source": [
        "## Examining the Distribution\n",
        "\n",
        "Returning to the overall statistics, the 90% percentile earns less than half the top percentile (\"the 1%\"); if you're taking home over £800 as a household, you're in the top 10% of earners.\n",
        "\n",
        "How does\n",
        "1. The income of \"the 1%\" compare with the mean and median across the population, as a proportion?\n",
        "2. How does the 1% compare with the 90th percentile (the 10%)?\n",
        "3. How does the 10% compare with the median and mean?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzeYPivlOglm"
      },
      "source": [
        "The 1% earn about 60 times the poorest groups in society - and we've made other comparisons. But that's not the whole story. Let's look at the income graph.\n",
        "\n",
        "In pandas, we can plot this fairly easily..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5CBXm8HOgln"
      },
      "outputs": [],
      "source": [
        "income['Net equivalised household income in 2010-11, week'].plot()\n",
        "plt.title('UK Net Equivalised Income by Percentile per week, 2010-11')\n",
        "plt.xlabel('Income Percentile')\n",
        "plt.ylabel('Income (Net, Equivalised) [GBP]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqLmgcUaOglp"
      },
      "source": [
        "We see a curve that is pretty linear in the middle region, but curves rapidly upwards in the higher percentile and looks more like a power law."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkC5oqwwOglp"
      },
      "source": [
        "### Exercise: Means\n",
        "\n",
        "Where does the mean appear here? Draw in a horizontal line to show the mean using **axhline**. Show the median on the same graph. What is the meaning of the median in this context?\n",
        "\n",
        "Hint: Recall that last time we used *axvline* to highlight the mean and standard deviation by drawing vertical lines on the axis. Here, we use *axhline* to draw horizontal lines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7_ZodE2Oglq"
      },
      "source": [
        "### Extension: Accessing cells\n",
        "\n",
        "There are a number of ways to access elements of the dataframe: we've shown how to access columns by the [*'name of column'*] method, and rows via the .loc[*index*] method; and how we can select a range. There are also .iloc methods to select by number rather than name; you should become familiar with these on the documentation page for pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB1-kYCeOglq"
      },
      "source": [
        "## Comparing segments\n",
        "\n",
        "Earlier, we compared some summary statistics of single people and couples. Let's look at the wider curve for more than one group, now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTfrHUP6Oglr"
      },
      "outputs": [],
      "source": [
        "#This is going to throw a load of errors\n",
        "income[['Single adult','Lone parent, one child under 14']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFLPCI8hOglt"
      },
      "source": [
        "## Warning\n",
        "\n",
        "This isn't looking good. There's a load of text and no graph. If you've not seen this before, it's an error - something has gone wrong. Generally, if we look at the **final** line, it should tell us what's wrong, in this case there's \"no numeric data to plot\", which is weird, because we've seen the data and have even plotted some of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b83Hwg61Oglu"
      },
      "source": [
        "## Messy Data\n",
        "\n",
        "DataFrames, as we are starting to see, give us the chance to plot, chop, slice and data to help us make sense of it. Here, we will create a **new** DataFrame to take only two columns of data, and get rid of any blank cells and any cells which are not being read as numbers - normally a sign of a missing value or a non-numerical character. Why could this be happening? It could be\n",
        "\n",
        "- due to blank spaces in the text file\n",
        "\n",
        "- due to letters where there should be numbers\n",
        "\n",
        "- due to characters (\",\", \"-\", etc) that shouldn't really be there\n",
        "\n",
        "In general, there will be some detective work required to figure out what's wrong in our text file. Your best bet is sometimes to open up the data in a text editor, like I've done here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLWfyIclOglu"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "data_path = \"https://s3.eu-west-2.amazonaws.com/qm2/wk2/data.png\"\n",
        "Image(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBz1Jv4kOglw"
      },
      "source": [
        "That's a screenshot of our datafile, opened up in a text editor. As we can see, these numbers are separated by commas and surrounded by quotation marks - this is normal, and what .csv files are supposed to look like. However, there are a lot of commas within the numbers - which makes it easier for people to read, but confuses software. Luckily, Python has a method for dealing with this - the \"replace\" method.\n",
        "\n",
        "Unfortunately, this dataframe is quite messy, so I'm going to have to extract just the columns of data I'm interested in to make it work. I'll do that by creating a new dataframe:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBxuM0aKOglx"
      },
      "source": [
        "## Example: Cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzCSbkcKOglx"
      },
      "outputs": [],
      "source": [
        "clean = income[['Childless couple, annual income','Couple, two children under 14']]\n",
        "clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8eg6tsDOglz"
      },
      "source": [
        "We see those pesky commas. Now we can get on with cleaning up the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YAEBL4aOgl0"
      },
      "outputs": [],
      "source": [
        "clean=clean.replace(',', '', regex=True)\n",
        "\n",
        "# In addition, missing values are sometimes written as '-', in order for Python to understand that it is just a missing numerical\n",
        "# value, all '-' need to be replaced with 'NaN'.\n",
        "clean = clean.replace('-', 'NaN', regex=True).astype('float')\n",
        "clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VNc0tutOgl2"
      },
      "source": [
        "**Extension**: \"**Regex**\" refers to \"**Reg**ular **Ex**pression\", which is a way of replacing and cleaning text. It's a bit beyond the scope of this class, but worth looking into if you're interested in programming more widely."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0dJN0OjOgl2"
      },
      "source": [
        "This seems to have done the job. We've also put a line in the code to get rid of dashes - a way that data collectors will sometimes represent missing data. Now let's plot this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DPJOfOnOgl2"
      },
      "source": [
        "## Asking more questions of the data\n",
        "For me, this data starts to beg further questions. How would we answer these?\n",
        "\n",
        "- If the top 20% of income shows such a sharp increase, how do we know that there isn't a similar uptick *within* the 1%? We've already seen that the mean of the dataset as a whole is much less than the half the maximum category (it's 25% of the maximum). What if that's true within the 1%, and £2,000/week as a fraction of the 0.1%, or the 0.01%?\n",
        "\n",
        "- How does this break down for gender, or educational background, or other factors like ethnicity or country of origin?\n",
        "\n",
        "- Which parts of the income curve show greater gaps between these subgroups and what might it say about the underlying causal mechanisms?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPSVukHaOgl3"
      },
      "outputs": [],
      "source": [
        "clean.plot()\n",
        "plt.title('A Modest Proposal: The fiscal benefits of childbirth')\n",
        "plt.xlabel('Percentile')\n",
        "plt.ylabel('Income Per Week [GBP]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TFQznjUOgl5"
      },
      "source": [
        "## Exercise:\n",
        "\n",
        "Previously, we'd examined income gaps between single people and couples (how very romantic). Repeat the above exercise (cleaning and plotting income data) for the columns we used above for single people and childless couples. Reflect and comment on the differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGlvHC7iOgl5"
      },
      "outputs": [],
      "source": [
        "# Step 1: Select the columns\n",
        "import pandas as pd\n",
        "data_path = \"./data/wk2/incomes.csv\"\n",
        "income =  pd.read_csv(data_path, index_col=0)\n",
        "income_comparison = income[['Single adult', 'Childless couple, annual income']]\n",
        "\n",
        "# Optional: Check your new DataFrame\n",
        "income_comparison.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbfcff4c"
      },
      "source": [
        "# Download the data again in case the runtime was reset\n",
        "!mkdir -p data/wk2\n",
        "!curl https://s3.eu-west-2.amazonaws.com/qm2/wk2/incomes.csv -o ./data/wk2/incomes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clean the data\n",
        "income_comparison_clean = income_comparison.replace(',', '', regex=True)\n",
        "income_comparison_clean = income_comparison_clean.replace('-', 'NaN', regex=True).astype('float')\n",
        "\n",
        "# Optional: Check the cleaned DataFrame\n",
        "income_comparison_clean.head()"
      ],
      "metadata": {
        "id": "GcBDJhLgYvgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Plot the data\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "income_comparison_clean.plot()\n",
        "plt.title('Income Comparison: Single Adult vs. Childless Couple')\n",
        "plt.xlabel('Percentile Point')\n",
        "plt.ylabel('Annual Income [GBP]')"
      ],
      "metadata": {
        "id": "iLRqAX_AYvXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtbGVYEkOgl8"
      },
      "outputs": [],
      "source": [
        "Add your reflection here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9fRF22DOgl-"
      },
      "source": [
        "So far, we've dealt with selecting data in a particular row of column by index or label. What if we now want to filter the data by *value*? For example, let's say I want to see the data for all Childless couples who earn more than 50,000 (net equivalised) pounds every year. This looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa1kaQwROgl_"
      },
      "outputs": [],
      "source": [
        "clean = income[['Childless couple, annual income','Couple, two children under 14']]\n",
        "clean = clean.replace(',', '', regex=True)\n",
        "clean = clean.replace('-', 'NaN', regex=True).astype('float')\n",
        "clean[clean['Childless couple, annual income']>50000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li_efWEHOgmA"
      },
      "source": [
        "The key line of code for selection is:\n",
        "\n",
        "```python\n",
        "clean[clean['Childless couple, annual income']>50000]\n",
        "```\n",
        "\n",
        "Let's break this down: we're used to using *dataframe*[*some selection*] from earlier. Here \"some selection\" is\n",
        "\n",
        "\n",
        "```python\n",
        "clean['Childless couple, annual income']>50000\n",
        "```\n",
        "\n",
        "In other words, this command is returning a set of indices where that statement is true. We can see this explicitly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DDpwa5wOgmB"
      },
      "outputs": [],
      "source": [
        "clean['Childless couple, annual income']>50000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voVyBM4dOgmD"
      },
      "source": [
        "So python is picking the values where this statement is true - i.e. where the 'Childless couple...' column has values greater than 50000. Then this selection is passed to the dataframe, and the dataframe shows the correct rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6E0bA_1OgmD"
      },
      "source": [
        "We won't dwell on comparative operative, here we've used \">\" to mean \"is greater than\"; you can also use:\n",
        "\n",
        "- == to mean 'is equal to' [why the double equals?]\n",
        "- <> or != to mean 'is not equal to'\n",
        "- < to mean 'is less than'\n",
        "- the symbol >= to mean 'is greater than or equal to'\n",
        "- <= to mean 'is less than or equal to'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlUpSnksOgmE"
      },
      "source": [
        "## Exercise\n",
        "On an approporiately labelled graph, plot the incomes of all single adults whose net equivalised income is less than or equal to £10,000. What proportion of the population is this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg_cvi27OgmE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l6qNsFHW0bL"
      },
      "source": [
        "# Extension: Web Scraping\n",
        "\n",
        "In this example, we've been working with a .csv file that contains all the data we want. That's not always the case. Let's say we're interested in getting the data from a table on a website. Websites are built using HTML code, so what we need to figure out how to look inside the website's code and pull out the data we want. Luckily, pandas has a built in function that can automatically recognize HTML tables in websites and turn them into dataframes.\n",
        "\n",
        "Let's start with the [Netflix Top 10](https://top10.netflix.com/) website. Click on the link and have a look around. You'll notice two tables: the first showing the top 10 films this week, and the second (farther down) showing the most popular filsms based on their first 28 days on netflix.\n",
        "\n",
        "We can download both of these tables into python using one pandas function: read_html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqFocmOrW0bM"
      },
      "outputs": [],
      "source": [
        "import pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the URL\n",
        "url = 'https://top10.netflix.com/'\n",
        "\n",
        "# Read all tables from the URL\n",
        "tables = pandas.read_html(url)"
      ],
      "metadata": {
        "id": "l5dsVF_UdZPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the list of tables\n",
        "print(tables)"
      ],
      "metadata": {
        "id": "AYd3mWTHdZMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first table from the list and assign it to a new variable\n",
        "top10 = tables[0]\n",
        "\n",
        "# Display the new DataFrame\n",
        "top10"
      ],
      "metadata": {
        "id": "d5w5Z8ZDdZIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the messy second column\n",
        "# top10.columns[1] selects the second column\n",
        "top10.rename(columns={top10.columns[1]: \"Title\"}, inplace=True)\n",
        "\n",
        "# Display the DataFrame again to see the fix\n",
        "top10"
      ],
      "metadata": {
        "id": "yTPGkTMbdZFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H6LQa6zsdZCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7miuQwkydYzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk-Zpy_cW0bM"
      },
      "source": [
        "When we print the results of what was scraped, it's pretty ugly. One of the reasons is that the `tables` variable is actually a *list* of dataframes. Because there were two tables on our website, `read_html` has returned both of those tables and put them in a list. let's save the first table as a new dataframe called `top10` and have a closer look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLyMtC3ZW0bN"
      },
      "outputs": [],
      "source": [
        "top10=tables[0]\n",
        "top10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KdjQEC7W0bN"
      },
      "source": [
        "This looks more like the dataframes we were looking at earlier. There's a big chunk of text (this is HTML code, the language websites are built with) where the name of the second column should be. `read_html` is usually pretty smart, and can actually read the column names from the tables on the website. It seems to have gotten confused for this one column. If we print the columns from the  We can rename that column using the `rename` function. Since we know it's the second column, we can select it with `top10.columns[1]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3cITeBHW0bN"
      },
      "outputs": [],
      "source": [
        "top10.rename(columns={top10.columns[1]: \"Title\" }, inplace = True)\n",
        "top10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRawowo9W0bO"
      },
      "source": [
        "And there we have it; a nicely formatted dataframe ready for analysis, straight from a website.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gOtczNOW0bO"
      },
      "source": [
        "# Assessed Question\n",
        "\n",
        "using this URL, `https://en.wikipedia.org/wiki/List_of_countries_by_traffic-related_death_rate`, calculate the average road fatalities per 100,000 inhabitants in Asia in 2019. Your answer should utilize the pandas `read_html` and `groupby` functions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import requests # <-- Add this import\n",
        "\n",
        "# Define the URL\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_traffic-related_death_rate'\n",
        "\n",
        "# Set headers to mimic a browser\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Fetch the page HTML using requests\n",
        "r = requests.get(url, headers=headers)\n",
        "\n",
        "# Check if the request was successful\n",
        "if r.status_code == 200:\n",
        "    print(\"Page fetched successfully!\")\n",
        "else:\n",
        "    print(f\"Error fetching page: Status code {r.status_code}\")"
      ],
      "metadata": {
        "id": "CwgeTHqXeH1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the HTML text (r.text) to pandas\n",
        "# We still use header=1 to get the correct column names\n",
        "tables = pandas.read_html(r.text, header=1)\n",
        "\n",
        "# Select the main data table (index 1) - This was incorrect, let's try index 0 and inspect\n",
        "df = tables[0]\n",
        "\n",
        "# Optional: check the first few rows\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "yyh3BcWafhj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the '2019' column to a numeric type\n",
        "# errors='coerce' turns any non-numeric values (like '—') into NaN\n",
        "# Based on the table structure, the column with 2019 data is likely 'Traffic-related death rate'\n",
        "df['2019_rate'] = pandas.to_numeric(df['15.0'], errors='coerce')\n",
        "\n",
        "# Optional: You can check the datatypes\n",
        "# df.info()"
      ],
      "metadata": {
        "id": "cHv7GH7wfpls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use groupby() to group the DataFrame by 'Continent'\n",
        "grouped_by_continent = df.groupby('Unnamed: 1')\n",
        "\n",
        "# Calculate the mean of our '2019_rate' column for each continent\n",
        "average_rates = grouped_by_continent['2019_rate'].mean()\n",
        "\n",
        "# Optional: See the averages for all continents\n",
        "print(\"Average rates by continent:\")\n",
        "print(average_rates)\n",
        "print(\"-\" * 30) # A separator line\n",
        "\n",
        "# Get the specific answer for Asia\n",
        "asia_average = average_rates.loc['Asia']\n",
        "\n",
        "print(f\"The average road fatalities in Asia is: {asia_average}\")"
      ],
      "metadata": {
        "id": "8i-SyozVfpf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdLClk0mfpct"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "W2. Working with Data in Pandas.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('geo')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ee0682e3aec3eb14c273afe4405335ee3a64a018407db16d950813fa3a05036"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}